---
layout: post
title: Hadoop学习经验之基本路线
description: Hadoop学习经验之基本路线
category: Hadoop
---

# Hadoop学习经验之基本路线
## <font color="red">Java基础</font>
1. 视频方面:
  + 推荐《毕向东JAVA基础视频教程》。学习hadoop不需要过度的深入，java学习到javase，在多线程和并行化多多理解实践即可。
2. 书籍方面:
 + 推荐李兴华的《java开发实战经典》

## <font color="red">Linux基础</font>
### 视频方面:
     1. 马哥的高薪Linux视频课程-Linux入门
     2. 兄弟连的新版Linux视频教程
     3. 老段的讲解鸟哥Linux基础+私房菜
     4. 老男孩的Linux
### 书籍方面:
	 1. 《鸟哥的linux私房菜》
	 2. 《鸟哥的服务架设篇》
	 3. 《Linux随身指南》
 	 4. 《老男孩Linux运维》
## <font color="red">Hadoop书籍</font>
	1. 《Hadoop实战  (第1版)  陆嘉恒》、《Hadoop实战  (第2版)  陆嘉恒》
	2. 《hadoop definitive guide 》中文书名是《Hadoop权威指南 （第1版）曾大聃译》，《Hadoop权威指南 (第2版) 周敏奇译》，《Hadoop权威指南 （第3版 ） 华东师范大学数据科学与工程学院译》
	3. Hadoop技术内幕：《深入解析Hadoop common和HDFS架构设计与实现原理》 蔡斌 
	4. hadoop技术内幕：《深入解析YARN架构设计与实现原理》董西成 
	5. Hadoop技术内幕：《深入理解MapReduce架构设计与实现原理》 董西成 
	6. 《Hadoop in Action》
	7. 《Hadoop应用开发技术详解    刘刚》
	8. 《Hadoop 核心技术》 翟周伟 

    # 平常多看看hadoop的官网，虽然是官网，但尽量多学习计算机方面的单词，对后续学习帮助极大。
    # 平常多看看他人的博客和社区论坛。
    # 平常多总结和做好笔记，及时回过头来再次多次整理。

## <font color="red">Maven书籍</font>
### 强烈推荐书籍：Maven实战   许晓斌著。目前是第一版 
## <font color="red">spark书籍</font>
	 1. 《Spark大数据处理  技术、应用与性能优化   高彦杰》
	 2. 《深入理解Spark核心思想与源码分析   耿嘉安》


#  **大数据是什么?**
### 有很多朋友问过我，大数据到底是什么？一句话来概括
- 针对非软件行业的朋友
  + 根据你平时在超市，加油站，饭店等地方的一些消费行为，通过大数据这个技术，我们可以知道你现在的年龄范围，是否婚配，是否有孩子，孩子大致是几岁，是否有固定住宅，车大致是什么价位的等信息。

- 针对软件行业的朋友
  + 平时我们写的程序都是在一台机器上运行，处理能力有限，当然，数据量也是有限的。大数据这个技术，其实就是可以实现把我们的代码分布在很多台机器上去并行处理海量的数据，然后从这些海量数据中获取有价值，有意义的信息。

#  **学习大数据需要的基本功**
- linux基础是必须的，最起码需要掌握linux命令行下的基本操作命令
- javase基础【包含mysql】，注意是javase，不是javaee。javaweb那一块的知识针对大数据工程师而言不是必须的

#  **大数据技术板块划分**
- 数据采集
  + flume kafka logstash filebeat ...
- 数据存储
  + mysql redis hbase hdfs ...
- 数据查询
  + hive impala elasticsearch kylin ...
- 数据计算
  + 实时计算
     + storm sparkstreaming flink ...
  + 离线计算
     + hadoop spark ...
- 其他框架
  + zookeeper ...

下面有一张图，大致列出来了大数据生态圈周边的一些技术框架[不够全面，仅供参考]

　　其实这张图中主要列出来了hadoop生态圈的框架，后期有时间的话重新整理一份完整的 。

#  **大数据学习步骤**
上面虽然列出来了很多框架，但是最开始学习的时候没必要全部都学，就算是在工作中，这些框架也不一定会全部用到。

　　下面我就大致列一下，各种框架的一个学习步骤吧：

　　 **注意：下面列出来的顺序只是个人建议，可以根据个人实际情况来调整顺序**

1. **linux基础和javase基础【包含mysql】**
	- 这些是基本功，刚开始也不可能学的很精通，最起码要对linux中的一些基本的命令混个脸熟，后面学习各种框架的时候都会用到，用多了就熟悉了。javase的话建议主要看面向对象，集合，io，多线程，以及jdbc操作即可。
2. **zookeeper**
	- zookeeper是很多大数据框架的基础，中文名称是动物园的意思，因为目前的大数据框架的图标很多都是动物的形状，所以zookeeper其实就是可以管理很多大数据框架的。针对这个框架，主要掌握如何搭建单节点和集群，以及掌握如何在zkcli客户端下对zookeeper的节点进行增删改查操作即可。
3. **hadoop**
	- 目前企业中一般都是用hadoop2.x的版本了，所以就没有必要再去学hadoop1.x版本了，hadoop2.x主要包含三大块
		+ hdfs  前期，主要学习hdfs的一些命令即可，上传，下载，删除，移动，查看等命令...
		+ mapreduce  这个需要重点学习下，要理解mr的原理以及代码实现，虽然现在工作中真正写mr的代码次数很少了，但是原理还是要理解的。
		+ yarn  前期了解即可，只需要知道yarn是一个资源调度平台，主要负责给任务分配资源即可，yarn不仅可以给mapreduce任务调度资源，还可以为spark任务调度资源...yarn是一个公共的资源调度平台，所有满足条件的框架都可以使用yarn来进行资源调度。
4. **hive**
	+ hive是一个数据仓库，所有的数据都是存储在hdfs上的，具体【数据仓库和数据库】的区别大家可以去网上搜索一下，有很多介绍。其实如果对mysql的使用比较熟悉的话，使用hive也就简单很多了，使用hive主要是写hql，hql是hive的sql语言，非常类似于mysql数据库的sql，后续学习hive的时候主要理解一些hive的语法特性即可。其实hive在执行hql，底层在执行的时候还是执行的mapredce程序。
	+ 注意：其实hive本身是很强大的，数据仓库的设计在工作中也是很重要的，但是前期学习的时候，主要先学会如何使用就好了。后期可以好好研究一下hive。
5. **hbase**
	+ hbase是一个nosql 数据库，是一个key-value类型的数据库，底层的数据存储在hdfs上。在学习hbase的时候主要掌握 row-key的设计，以及列簇的设计。要注意一个特点就是，hbase基于rowkey查询效率很快，可以达到秒级查询，但是基于列簇中的列进行查询，特别是组合查询的时候，如果数据量很大的话，查询性能会很差。
6. **redis**
	+ redis也是一个nosql 数据库和key-value类型的数据库，但是这个数据库是纯基于内存的，也就是redis数据库中的数据都是存储在内存中的，所以它的一个特点就是适用于快速读写的应用场景，读写可以达到10W次/秒，但是不适合存储海量数据，毕竟机器的内存是有限的，当然，redis也支持集群，也可以存储大量数据。在学习redis的时候主要掌握string，list，set，sortedset，hashmap这几种数据类型的区别以及使用，还有pipeline管道，这个在批量入库数据的时候是非常有用的，以及transaction事务功能。
7. **flume**
	+ flume是一个日志采集工具，这个还是比较常用的，最常见的就是采集应用产生的日志文件中的数据。一般有两个流程，一个是flume采集数据存储到kafka中，为了后面使用storm或者sparkstreaming进行实时处理。另一个流程是flume采集的数据落盘到hdfs上，为了后期使用hadoop或者spark进行离线处理。在学习flume的时候其实主要就是学会看flume官网的文档，学习各种组建的配置参数，因为使用flume就是写各种的配置。
8. **kafka**
	+ kafka 是一个消息队列，在工作中常用于实时处理的场景中，作为一个中间缓冲层，例如，flume->kafka->storm/sparkstreaming。学习kafka主要掌握topic，partition，replicate等的概念和原理。
9. **storm**
	+ storm是一个实时计算框架，和hadoop的区别就是，hadoop是对离线的海量数据进行处理，而storm是对实时新增的每一条数据进行处理，是一条一条的处理，可以保证数据处理的时效性。学习storm主要学习topology的编写，storm并行度的调整，以及storm如何整合kafka实时消费数据。
10. **spark**
	+ spark 现在发展的也很不错，也发展成了一个生态圈，spark里面包含很多技术，spark core，spark steaming，spark mlib，spark graphx。
	+ spark生态圈里面包含的有离线处理spark core，和实时处理spark streaming，在这里需要注意一下，storm和spark streaming ，两个都是实时处理框架，但是主要区别是：storm是真正的一条一条的处理，而spark streaming 是一批一批的处理。
	+ spark中包含很多框架，在刚开始学习的时候主要学习spark core和spark streaming即可。这个一般搞大数据的都会用到。spark mlib和spark graphx 可以等后期工作需要或者有时间了在研究即可。
11. **elasticsearch**
	+ elasticsearch是一个适合海量数据实时查询的全文搜索引擎，支持分布式集群，其实底层是基于lucene的。在查询的时候支持快速模糊查询，求count，distinct，sum，avg等操作，但是不支持join操作。elasticsearch目前也有一个生态圈，elk(elasticsearch logstash kibana)是一个典型的日志收集，存储，快速查询出图表的一整套解决方案。在学习elasticsearch的时候，前期主要学习如何使用es进行增删改查，es中的index，type，document的概念，以及es中的mapping的设计。

#### 转载请注明出处：[https://www.cnblogs.com/zlslch/p/5448857.html#top](https://www.cnblogs.com/zlslch/p/5448857.html#top)

